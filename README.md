# Code experiemnts for AIiH 2025 Abtract: A Comparison of Potentials and Limitations of Transformer Models for Aspect-based Medical Sentiment Analysis
Transformer models have gained attention for tasks like sentiment analysis. This study explores the potential and limitations of
RoBERTa-XLM and GPT-2 for aspect-based sentiment analysis using the Swiss Sleep Database. While effective, these models face challenges
in when analysing sentiment in clinical texts. We conclude, that techniques like fine-tuning, data balancing, expert-driven normalization, and
negation-aware processing are essential for improving performance in medical contexts.

![gpt2](https://github.com/user-attachments/assets/a13f1ca3-c938-44b0-bd94-1c9828d7dffd)


<img width="1112" alt="Bildschirmfoto 2025-04-10 um 23 15 33" src="https://github.com/user-attachments/assets/cf0222d6-5ffa-431f-8d1d-66febe7dc335" />

