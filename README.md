# Code experiemnts for AIME2025 paper A Comparison of Potentials and Limitations of Transformer Models for Aspect-based Medical Sentiment Analysis
Transformer models have gained attention for tasks like sentiment analysis. This study explores the potential and limitations of
RoBERTa-XLM and GPT-2 for aspect-based sentiment analysis using the Swiss Sleep Database. While effective, these models face challenges
in when analysing sentiment in clinical texts. We conclude, that techniques like fine-tuning, data balancing, expert-driven normalization, and
negation-aware processing are essential for improving performance in medical contexts.
