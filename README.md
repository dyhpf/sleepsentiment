# Code experiemnts for AIiH 2025 Abtract: A Comparison of Potentials and Limitations of Transformer Models for Aspect-based Medical Sentiment Analysis
Transformer models have gained attention for tasks like sentiment analysis. This study explores the potential and limitations of
RoBERTa-XLM and GPT-2 for aspect-based sentiment analysis using the Swiss Sleep Database. While effective, these models face challenges
in when analysing sentiment in clinical texts. We conclude, that techniques like fine-tuning, data balancing, expert-driven normalization, and
negation-aware processing are essential for improving performance in medical contexts.
<img width="1125" alt="tokensize" src="https://github.com/user-attachments/assets/9f548dfb-f1bb-44c3-b638-7ec02ef4bc84" />
<img width="1114" alt="gpt2" src="https://github.com/user-attachments/assets/7a5818d9-ddb1-4e9c-bf22-3d999798e5bf" />
